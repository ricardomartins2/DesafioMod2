{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c710f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\dcemricardo\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\dcemricardo\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d2e54",
   "metadata": {},
   "source": [
    "### *Iniciando uma sessão*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2ef098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e503a37",
   "metadata": {},
   "source": [
    "### *Criando um DF apartir de um arquivo csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5fe3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('stroke_data.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68b5ed9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  0|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level|  bmi| smoking_status|stroke|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  1|Female|18.0|           0|            0|          No|      Private|         Urban|            94.19|12.12|         smokes|     1|\n",
      "|  2|  Male|58.0|           1|            0|         Yes|      Private|         Rural|           154.24| 33.7|   never_smoked|     0|\n",
      "|  3|Female|36.0|           0|            0|         Yes|     Govt_job|         Urban|            72.63| 24.7|         smokes|     0|\n",
      "|  4|Female|62.0|           0|            0|         Yes|Self-employed|         Rural|            85.52| 31.2|formerly smoked|     0|\n",
      "|  5|Female|82.0|           0|            0|         Yes|      Private|         Rural|            59.32| 33.2|         smokes|     1|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0215b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros:  67135\n"
     ]
    }
   ],
   "source": [
    "print('Total de registros: ', df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee96df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando total de colunas e sua tipagem\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "631482cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|stroke|count|\n",
      "+------+-----+\n",
      "|     1|40287|\n",
      "|     0|26848|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# quantos pacientes sofreram e não sofreram derrame (stroke), respectivamente\n",
    "df.groupby('stroke').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bafe477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de pacientes que tiveram derrame por tipo de trabalho (work_type): \n",
      "+-------------+-----+\n",
      "|    work_type|total|\n",
      "+-------------+-----+\n",
      "|      Private|23711|\n",
      "|Self-employed|10807|\n",
      "|     Govt_job| 5164|\n",
      "|     children|  520|\n",
      "| Never_worked|   85|\n",
      "+-------------+-----+\n",
      "\n",
      "Total de crianças: \n",
      "+---------+-----+\n",
      "|work_type|total|\n",
      "+---------+-----+\n",
      "| children|  520|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A partir do dataframe, crie uma tabela temporária usando df.createOrReplaceTempView('table') e a seguir \n",
    "#use spark.sql para escrever uma consulta SQL que obtenha quantos pacientes tiveram derrame \n",
    "#por tipo de trabalho (work_type). \n",
    "#Quantos pacientes sofreram derrame e trabalhavam respectivamente, no setor privado, de forma independente, \n",
    "#no governo e quantas são crianças? \n",
    "\n",
    "df.createOrReplaceTempView('temp')\n",
    "print('Total de pacientes que tiveram derrame por tipo de trabalho (work_type): ')\n",
    "spark.sql('select work_type, count(*) as '\"total\"' from temp where stroke = 1 group by work_type order by total desc').show()\n",
    "\n",
    "print('Total de crianças: ')\n",
    "spark.sql('select work_type, count(*) as '\"total\"' from temp where stroke = 1 and work_type=\"children\" group by work_type').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f17ccc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total por gênero: \n",
      "+------+-----+\n",
      "|gender|total|\n",
      "+------+-----+\n",
      "|Female|39530|\n",
      "|  Male|27594|\n",
      "| Other|   11|\n",
      "+------+-----+\n",
      "\n",
      "Proporção por gênero(%): \n",
      "+----+------+-----+\n",
      "|Male|Female|Other|\n",
      "+----+------+-----+\n",
      "|41.0|  59.0|  0.0|\n",
      "+----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Escreva uma consulta com spark.sql para determinar a proporção, por gênero, de participantes do estudo. \n",
    "# A maioria dos participantes é: \n",
    "\n",
    "print(\"Total por gênero: \")\n",
    "spark.sql('select gender, count(*) as total from temp group by gender order by total desc').show()\n",
    "\n",
    "print(\"Proporção por gênero(%): \")\n",
    "spark.sql('select round((Male/Total),2)*100 as '\"Male\"',\\\n",
    "                  round((Female/Total),2)*100 as '\"Female\"',\\\n",
    "                  round((Other/Total),2)*100 as '\"Other\"'\\\n",
    "           From\\\n",
    "                  (select SUM(CASE WHEN gender = \"Male\" THEN 1 ELSE 0 END) as '\"Male\"', \\\n",
    "                          SUM(CASE WHEN gender = \"Female\" THEN 1 ELSE 0 END) as '\"Female\"', \\\n",
    "                          SUM(CASE WHEN gender = \"Other\" THEN 1 ELSE 0 END) as '\"Other\"', \\\n",
    "                          COUNT(*) AS '\"Total\"' from temp)').show()\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f14aa5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporção de pacientes SEM hipertensão: \n",
      "+------------+------+-----+\n",
      "|hypertension|stroke|total|\n",
      "+------------+------+-----+\n",
      "|           0|     1|31470|\n",
      "|           0|     0|24648|\n",
      "|           1|     1| 8817|\n",
      "|           1|     0| 2200|\n",
      "+------------+------+-----+\n",
      "\n",
      "Proporção de pacientes COM hipertensão: \n"
     ]
    }
   ],
   "source": [
    "#Escreva uma consulta com spark.sql para determinar quem tem mais probabilidade de sofrer derrame: hipertensos ou não-hipertensos. \n",
    "#Você pode escrever uma consulta para cada grupo. A partir das probabilidades que você obteve, você conclui que:\n",
    "hyper_no=spark.sql('select * from temp where hypertension = 0')\n",
    "hyper_yes=spark.sql('select * from temp where hypertension = 1')\n",
    "\n",
    "print('Proporção de pacientes SEM hipertensão: ')\n",
    "spark.sql('select hypertension,stroke, count(*) as total from temp group by stroke, hypertension order by hypertension').show()\n",
    "\n",
    "\n",
    "print('Proporção de pacientes COM hipertensão: ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582b1ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| age|total|\n",
      "+----+-----+\n",
      "|79.0| 2916|\n",
      "|78.0| 2279|\n",
      "|80.0| 1858|\n",
      "|81.0| 1738|\n",
      "|82.0| 1427|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Escreva uma consulta com spark.sql que determine o número de pessoas que sofreram derrame por idade.\n",
    "# Com qual idade o maior número de pessoas do conjunto de dados sofreu derrame?\n",
    "\n",
    "spark.sql('select age, count(*) as total from temp where stroke = 1 group by age order by total desc').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d418aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28938"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando a API de dataframes, determine quantas pessoas sofreram derrames após os 50 anos.\n",
    "df.filter((df.age > 50.0) & (df.stroke == 1)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24156d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|sofreram|Nsofreram|\n",
      "+--------+---------+\n",
      "|  119.95|    103.6|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usando spark.sql, determine qual o nível médio de glicose para pessoas que, respectivamente, \n",
    "# sofreram e não sofreram derrame.\n",
    "spark.sql('select * from (select round(avg(avg_glucose_level),2) sofreram from temp where stroke = 1),\\\n",
    "                         (select round(avg(avg_glucose_level),2) Nsofreram from temp where stroke = 0)').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fceae1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|sofreram|Nsofreram|\n",
      "+--------+---------+\n",
      "|   29.94|    27.99|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Qual é o BMI (IMC = índice de massa corpórea) médio de quem sofreu e não sofreu derrame?\n",
    "\n",
    "spark.sql('select * from (select round(avg(bmi),2) sofreram from temp where stroke = 1),\\\n",
    "                         (select round(avg(bmi),2) Nsofreram from temp where stroke = 0)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93382ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6927229108356657\n"
     ]
    }
   ],
   "source": [
    "# Crie um modelo de árvore de decisão que prevê a chance de derrame (stroke) a partir das variáveis contínuas/categóricas: idade, BMI, hipertensão, doença do coração, nível médio de glicose. \n",
    "# Use o conteúdo da segunda aula interativa para criar e avaliar o modelo.\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "# usando colunas numericas/categóricas\n",
    "numericCols=['age','bmi','hypertension','heart_disease','avg_glucose_level']\n",
    "vecAssembler=VectorAssembler(inputCols=numericCols, outputCol='features')\n",
    "\n",
    "#Executar o algoritmo Decision Tree\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(labelCol='stroke',featuresCol='features')\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[vecAssembler, dtc])\n",
    "\n",
    "# Separar os dados em treinamento e teste\n",
    "train_data, test_data = df.randomSplit([0.7,0.3])\n",
    "\n",
    "# recebe o DF e produz o modelo\n",
    "pipelineModel = pipeline.fit(train_data) \n",
    "\n",
    "# aplica o modelo aos dados de teste\n",
    "predictionsDF = pipelineModel.transform(test_data)\n",
    "\n",
    "# verificar a qualidade do modelo\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', labelCol='stroke') \n",
    "print(f'Acurácia: {evaluator.evaluate(predictionsDF)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "975640f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione ao modelo as variáveis categóricas: gênero e status de fumante. Use o conteúdo da aula interativa para lidar com as variáveis categóricas.  \n",
    "# A acurácia (qualidade) do modelo aumentou para:\n",
    "\n",
    "categoricalCols = ['gender','smoking_status']\n",
    "# converter as colunas string para inteiros\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=[x + 'Index' for x in categoricalCols])\n",
    "oneHotEncoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[x + 'OHE' for x in categoricalCols])\n",
    "\n",
    "allCols = [c + 'OHE' for c in categoricalCols] + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=allCols, outputCol='features')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "648ec405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8322339273407502\n"
     ]
    }
   ],
   "source": [
    "# Ao construirmos e avaliarmos o novo modelo, veja que a qualidade das previsões melhorou um pouco, após adicionarmos os atributoscategóricos:\n",
    "pipeline = Pipeline(stages=[stringIndexer,oneHotEncoder,vecAssembler, dtc])\n",
    "\n",
    "# Separar os dados em treinamento e teste\n",
    "train_data, test_data = df.randomSplit([0.7,0.3])\n",
    "\n",
    "# recebe o DF e produz o modelo\n",
    "pipelineModel = pipeline.fit(train_data) \n",
    "\n",
    "# aplica o modelo aos dados de teste\n",
    "predictionsDF = pipelineModel.transform(test_data)\n",
    "\n",
    "# verificar a qualidade do modelo\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', labelCol='stroke') \n",
    "print(f'Acurácia: {evaluator.evaluate(predictionsDF)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
